# üéØ Agent Orchestration System Guide

**Professional multi-agent coordination system like you saw in the video**

## What You're Getting

Based on the video workflow you showed me, I've created a **2-level monitoring system**:

### Level 1: Simple Monitoring (What we set up first)
- Shows which scrapers are running
- Displays latest results
- Basic system metrics

### Level 2: Agent Orchestration (Advanced - Like the video)
- **PM Coordination**: Shows what the Project Manager is coordinating
- **Specialized Agents**: 4 agents with specific roles
- **Task Complexity Scoring**: Shows computational cost (like "tokens" in video)
- **Quality Validation**: Real-time data quality monitoring
- **Next Action Planning**: PM determines what should happen next

---

## Quick Start: Agent Orchestration Mode

### Setup (One-Time)

**1. Split Terminal in Cursor**
- Click split terminal icon OR press `Cmd+\`
- You get left pane (PM/Chat) + right pane (Agents)

**2. Right Pane - Start Agent Orchestration**
```bash
./scripts/start_orchestration.sh
```

**3. Left Pane - Keep for PM Communication**
- This is where you talk to me (the PM)
- I coordinate which agents to activate
- You run commands here

---

## What Each Agent Does

### üîµ SCRAPER AGENT
**Role**: Initial data extraction from 237 TikTok URLs

**What it does**:
- Loads cookies for authentication
- Intercepts TikTok API responses
- Extracts 43 columns of data
- Processes URLs in batches of 10

**Activate**:
```bash
source venv/bin/activate
python 02_Scraping_Systems/01_TikTok_Scrapers/production_scraper_237_urls.py
```

**Complexity**: 25/100 tokens

---

### üü° RECOVERY AGENT
**Role**: Retry failed URLs with intelligent fallback

**What it does**:
- Takes URLs that failed in initial scrape
- Attempts video-level scraping first
- Falls back to account-level scraping if video fails
- Resolves short URLs to get usernames

**Activate**:
```bash
source venv/bin/activate
python 02_Scraping_Systems/01_TikTok_Scrapers/retry_failed_with_account_scraping.py
```

**Complexity**: 25/100 tokens

---

### üü¢ ENRICHMENT AGENT
**Role**: Fill missing account metadata

**What it does**:
- Finds all unique usernames with 0 followers
- Visits each account profile page
- Extracts: followers, following, posts, verified status
- Updates CSV with enriched data

**Activate** (Currently Running):
```bash
source venv/bin/activate
python 02_Scraping_Systems/01_TikTok_Scrapers/enrich_account_data.py
```

**Complexity**: 25/100 tokens

---

### üîç VALIDATOR AGENT
**Role**: Continuous quality monitoring

**What it does**:
- Automatically monitors latest CSV
- Calculates quality score (% with data)
- Reports: EXCELLENT (90%+), GOOD (70-90%), NEEDS IMPROVEMENT (<70%)
- No manual activation needed - always monitoring

**Complexity**: 25/100 tokens (passive monitoring)

---

## Understanding "Tokens" and Complexity

In the video you saw "64s ¬∑ 1.2k tokens" at the bottom. Here's what that means:

### What Are Tokens?
- **Tokens** = Units of text processing
- Roughly 4 characters = 1 token
- "Hello world" = ~3 tokens
- More complex tasks = more tokens

### In Our System:
- **Task Complexity Score**: 0-100 based on active agents
- 1 agent active = 25/100 complexity
- 4 agents active = 100/100 complexity
- Helps you understand computational cost

### Real-World Example:
```
Simple task: "What time is it?" ‚Üí 5 tokens
Complex task: "Scrape 237 URLs with fallback strategies" ‚Üí 1,200+ tokens
```

---

## PM Coordination Workflow

I act as the **Project Manager** coordinating agents. Here's how it works:

### Stage 1: Initial Planning
**PM (Me)**: "We need to scrape 237 URLs with 43 columns of data"

**Decision**:
- Activate: SCRAPER AGENT
- Task: Process all URLs with API interception
- Expected Output: CSV with 90%+ success rate

### Stage 2: Recovery
**PM (Me)**: "12 URLs failed - activate recovery protocol"

**Decision**:
- Activate: RECOVERY AGENT
- Task: Retry with account fallback
- Expected Output: Increase success to 95%+

### Stage 3: Enrichment
**PM (Me)**: "223 videos have usernames but 0 followers - enrich data"

**Decision**:
- Activate: ENRICHMENT AGENT
- Task: Scrape 158 unique account profiles
- Expected Output: Complete account metadata

### Stage 4: Validation
**PM (Me)**: "Check final data quality"

**Decision**:
- Activate: VALIDATOR AGENT
- Task: Calculate quality score and report
- Expected Output: Quality assessment

---

## Live Example: Current Session

**What's Happening Right Now**:

```
ü§ñ SPECIALIZED AGENTS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚≠ï SCRAPER AGENT        : STANDBY (Completed: 223/235 URLs)
‚≠ï RECOVERY AGENT      : STANDBY (Completed: Recovered 9/12 URLs)
‚úÖ ENRICHMENT AGENT    : ACTIVE (Processing: 14/158 accounts)
üîç VALIDATOR AGENT     : MONITORING (Quality: 85% - GOOD)

üìä SYSTEM METRICS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Active Agents: 1/4
Task Complexity: 25/100
CPU Usage: 12.4%
Memory: 35GB

üéØ PM COORDINATION:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üîÑ Data enrichment in progress
   Next: Database import preparation
```

**Translation**:
- PM coordinated 3 agents sequentially
- Currently: ENRICHMENT AGENT working on accounts
- Next: Once enrichment complete, prepare database import
- Task is 25% complex (1 agent active)

---

## Advanced Usage

### Running Multiple Agents in Parallel

**Left Pane (PM Communication)**:
```bash
# Terminal 1: You communicate with PM (me)
# I coordinate which agents to run and when
```

**Right Pane (Agent Monitor)**:
```bash
# Shows real-time agent activity
./scripts/start_orchestration.sh
```

**Watch the orchestration system show**:
- Which agents are ACTIVE vs STANDBY
- Current task for each agent
- PM's next planned action
- System resource usage

### Task Queue System (Future Enhancement)

The video showed task queues. You can enable this by creating `.agent_tasks`:

```bash
echo "TASK-001: Scrape remaining URLs" >> .agent_tasks
echo "TASK-002: Enrich account data" >> .agent_tasks
echo "TASK-003: Validate data quality" >> .agent_tasks
```

The orchestrator will display this queue and check off tasks as agents complete them.

---

## Comparison: Simple vs Orchestration Mode

### Simple Monitoring (`monitor_agents.sh`)
**Good for**:
- Quick status checks
- Watching one scraper run
- Basic file output tracking

**Shows**:
- ‚úÖ RUNNING or ‚≠ï IDLE
- Latest CSV file
- Success rate %
- CPU/Memory

### Agent Orchestration (`start_orchestration.sh`)
**Good for**:
- Complex multi-agent workflows
- Understanding PM coordination
- Task complexity analysis
- Professional GitHub-style setup

**Shows**:
- All 4 specialized agents with roles
- What each agent is doing (task details)
- PM's coordination decisions
- Next planned action
- Task complexity scoring
- Quality validation

---

## Tips for Professional Setup

### 1. Resize Your Panes
- **Left pane**: 60-70% width (main work area)
- **Right pane**: 30-40% width (monitoring)

### 2. Color Interpretation
- **Green (‚úÖ)**: Agent is actively working
- **Yellow (‚≠ï)**: Agent on standby, ready to activate
- **Blue (üîç)**: Passive monitoring agent
- **Red**: Errors or quality issues

### 3. Use PM for Decision Making
**Instead of**:
```bash
# Running scripts randomly
python script1.py
python script2.py
python script3.py
```

**Do This**:
```
You (to PM): "I want to scrape the URLs and get complete data"

PM (Me): "I'll coordinate a 3-agent workflow:
1. SCRAPER AGENT: Initial extraction
2. RECOVERY AGENT: Handle failures
3. ENRICHMENT AGENT: Complete metadata
Watch the right pane for real-time progress"
```

### 4. Token Awareness
Check the **Task Complexity** score:
- **0-25**: Simple, fast operations
- **25-50**: Moderate complexity
- **50-75**: Complex multi-agent coordination
- **75-100**: Maximum complexity (all agents working)

Higher complexity = longer execution time but more thorough results

---

## Current Project Status

### Completed Stages ‚úÖ
1. **SCRAPER AGENT**: 223/235 URLs (94.9% success) ‚úÖ
2. **RECOVERY AGENT**: Recovered 9/12 failed URLs (98.7% total) ‚úÖ

### Active Stage üîÑ
3. **ENRICHMENT AGENT**: 14/158 accounts enriched (in progress)

### Pending Stages ‚è≥
4. **VALIDATOR AGENT**: Will run after enrichment completes
5. **Database Import**: Final stage after validation

### Expected Final Results
- **262 total videos**
- **~250+ with complete data** (95%+ success)
- **All account metadata** (followers, posts, verified)
- **Ready for database import**

---

## Troubleshooting

### "No agents showing in monitor"
Check if processes are running:
```bash
ps aux | grep -E "scraper|retry|enrich"
```

### "Complexity always shows 0"
No agents are active. Activate an agent from the left pane.

### "Can't see PM coordination section"
The orchestrator determines next action based on active agents. If nothing is running, it shows "awaiting instructions".

### Monitor not updating
The orchestrator refreshes every 3 seconds. Wait a moment or restart:
```bash
Ctrl+C (stop)
./scripts/start_orchestration.sh (restart)
```

---

## Next Steps

1. **Let ENRICHMENT AGENT complete** (~2-3 hours for 158 accounts)
2. **Watch orchestrator show progress** in real-time
3. **PM will coordinate database import** once data is complete
4. **Use this setup for future projects** - it's reusable!

**You now have a professional GitHub-style agent orchestration system!** üéØ
